{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ETL Process for order_info_by_neighbourhood"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aaa4f96df6b2784"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract and Transforming using PySpark"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b096b09bfb6b2e0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start Spark Session"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4159e5cf21efe8bf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import FloatType"
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-04-28T07:42:34.856289Z",
     "start_time": "2024-04-28T07:42:34.470956Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c434ade904cfae",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:42:36.601856Z",
     "start_time": "2024-04-28T07:42:34.857160Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/28 03:42:35 WARN Utils: Your hostname, Kun-Mac.local resolves to a loopback address: 127.0.0.1; using 172.20.23.178 instead (on interface en0)\n",
      "24/04/28 03:42:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/28 03:42:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apache Spark Version 3.5.0\n",
      "Spark UI is available at: http://172.20.23.178:4040\n"
     ]
    }
   ],
   "source": [
    "# running local spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\")\\\n",
    "    .appName(\"neighborhoods_and_city\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(\"Using Apache Spark Version\", spark.version)\n",
    "web_ui_url = sc.uiWebUrl\n",
    "print(f\"Spark UI is available at: {web_ui_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad0937443f13bc73"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748f96ad2304bf6b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:42:40.592364Z",
     "start_time": "2024-04-28T07:42:36.600437Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "listings = spark.read.option(\"header\", \"true\") \\\n",
    "                    .option(\"delimiter\", \",\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .option(\"multiLine\", \"true\")\\\n",
    "                    .option(\"escape\", \"\\\"\")\\\n",
    "                    .csv(\"../Data/listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fd7aec8e1b1fcb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:44:00.462222Z",
     "start_time": "2024-04-28T07:42:40.593726Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/28 03:42:46 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "calendar = spark.read.option(\"header\", \"true\") \\\n",
    "                    .option(\"delimiter\", \",\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .option(\"multiLine\", \"true\")\\\n",
    "                    .option(\"escape\", \"\\\"\")\\\n",
    "                    .csv(\"../Data/calendar.csv\")\n",
    "calendar = calendar.drop(*['minimum_nights','maximum_nights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transforming process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e95574a7771d9ad"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dee41ed38da655",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:44:00.491405Z",
     "start_time": "2024-04-28T07:44:00.461131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<function __main__.money_to_float(money_str)>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def money_to_float(money_str):\n",
    "    if money_str is None:\n",
    "        return None\n",
    "    else:\n",
    "        cleaned_str = money_str[1:].replace(',', '')\n",
    "        return float(cleaned_str)\n",
    "spark.udf.register(\"money_to_float_udf\", money_to_float, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918f1e1280e44e5d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:44:00.787439Z",
     "start_time": "2024-04-28T07:44:00.492840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/28 03:44:00 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "listings.createOrReplaceTempView('listings')\n",
    "calendar.createOrReplaceTempView('calendar')\n",
    "sql = '''\n",
    "with neighbourhood as ( \n",
    "select\n",
    "    id\n",
    "    ,city\n",
    "    ,state\n",
    "    ,neighbourhood_cleansed\n",
    "from listings l\n",
    "),\n",
    "calendar_cleaned as ( \n",
    "select\n",
    "    listing_id\n",
    "    ,date\n",
    "    ,if(available='t',1,0) as is_available\n",
    "    ,coalesce(money_to_float_udf(adjusted_price),money_to_float_udf(price)) as price\n",
    "from calendar\n",
    ")\n",
    "\n",
    "select\n",
    "    t2.state\n",
    "    ,t2.city\n",
    "    ,t2.neighbourhood_cleansed\n",
    "    ,date\n",
    "    ,sum(is_available)/count(is_available) as occupancy_rate\n",
    "    ,avg(price) as avg_price\n",
    "from calendar_cleaned t1\n",
    "left join neighbourhood t2\n",
    "    on t1.listing_id = t2.id\n",
    "group by \n",
    "    t2.state\n",
    "    ,t2.city\n",
    "    ,t2.neighbourhood_cleansed\n",
    "    ,date\n",
    "'''\n",
    "result_neighbourhood = spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3942be803292ac96",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:48:22.609464Z",
     "start_time": "2024-04-28T07:44:00.785475Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/28 03:45:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:45:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/28 03:48:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:48:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "  state           city neighbourhood_cleansed        date  occupancy_rate  \\\n0    ny  new-york-city               Flatbush  2024-03-16        0.442913   \n1    ny  new-york-city               Flatbush  2024-09-15        0.427165   \n2    ny  new-york-city               Flatbush  2024-11-23        0.336614   \n3    ny  new-york-city           East Village  2024-02-17        0.234043   \n4    ny  new-york-city           East Village  2024-04-23        0.307123   \n\n    avg_price  \n0  125.580709  \n1  125.580709  \n2  125.580709  \n3  241.274746  \n4  241.274746  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>city</th>\n      <th>neighbourhood_cleansed</th>\n      <th>date</th>\n      <th>occupancy_rate</th>\n      <th>avg_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ny</td>\n      <td>new-york-city</td>\n      <td>Flatbush</td>\n      <td>2024-03-16</td>\n      <td>0.442913</td>\n      <td>125.580709</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ny</td>\n      <td>new-york-city</td>\n      <td>Flatbush</td>\n      <td>2024-09-15</td>\n      <td>0.427165</td>\n      <td>125.580709</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ny</td>\n      <td>new-york-city</td>\n      <td>Flatbush</td>\n      <td>2024-11-23</td>\n      <td>0.336614</td>\n      <td>125.580709</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ny</td>\n      <td>new-york-city</td>\n      <td>East Village</td>\n      <td>2024-02-17</td>\n      <td>0.234043</td>\n      <td>241.274746</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ny</td>\n      <td>new-york-city</td>\n      <td>East Village</td>\n      <td>2024-04-23</td>\n      <td>0.307123</td>\n      <td>241.274746</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result_neighbourhood.count())\n",
    "result_neighbourhood.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d595dcbfe00ec2",
   "metadata": {},
   "source": [
    "# Insert into Database\n",
    "- result_neighbourhood to PostgreSQL table \"order_info_by_neighbourhood\""
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "### Connecting Postgresql"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72258139532d5ba3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4698c04f0056df27",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:48:23.073989Z",
     "start_time": "2024-04-28T07:48:22.614337Z"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "\n",
    "# Pass the connection string to a variable, conn_url\n",
    "conn_url = 'postgresql://postgres:123@localhost:5432/airbnb'\n",
    "\n",
    "# Create an engine that connects to PostgreSQL server\n",
    "engine = create_engine(conn_url)\n",
    "\n",
    "# Establish a connection\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eab2a086e7f15dc8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# creating table\n",
    "# all the column except primary key can take null value\n",
    "sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS order_info_by_neighbourhood (\n",
    "    state VARCHAR(10), \n",
    "    city VARCHAR(255),\n",
    "    neighbourhood_cleansed VARCHAR(255),\n",
    "    date DATE,\n",
    "    occupancy_rate DOUBLE PRECISION,\n",
    "    avg_price DOUBLE PRECISION,\n",
    "    PRIMARY KEY (state, city, neighbourhood_cleansed, date),\n",
    "    FOREIGN KEY (state, city, neighbourhood_cleansed) REFERENCES neighbourhood(state,city, neighbourhood_cleansed)\n",
    ");\n",
    "\"\"\"\n",
    "connection.execute(text(sql))\n",
    "connection.commit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:48:23.109269Z",
     "start_time": "2024-04-28T07:48:23.074891Z"
    }
   },
   "id": "e9fa3e30225305a8",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:51 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/04/28 03:50:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pd_df = result_neighbourhood.toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:51:03.149798Z",
     "start_time": "2024-04-28T07:48:23.109828Z"
    }
   },
   "id": "8c700217c419074a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "975"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.dropna(subset=['neighbourhood_cleansed'],inplace=True)\n",
    "pd_df.to_sql(name='order_info_by_neighbourhood', con=engine, if_exists='append', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:51:17.370686Z",
     "start_time": "2024-04-28T07:51:03.149636Z"
    }
   },
   "id": "3dc72940fe961ce6",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:51:17.376262Z",
     "start_time": "2024-04-28T07:51:17.369432Z"
    }
   },
   "id": "879befc66a924f02",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
