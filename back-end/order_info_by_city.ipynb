{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-04-27T20:18:00.042038Z",
     "start_time": "2024-04-27T20:17:59.624804Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c434ade904cfae",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:18:01.880141Z",
     "start_time": "2024-04-27T20:18:00.042835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/27 16:18:01 WARN Utils: Your hostname, Kun-Mac.local resolves to a loopback address: 127.0.0.1; using 10.206.101.44 instead (on interface en0)\n",
      "24/04/27 16:18:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/27 16:18:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# running local spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\")\\\n",
    "    .appName(\"neighborhoods_and_city\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "768927c96924b764",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:18:01.883745Z",
     "start_time": "2024-04-27T20:18:01.880946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apache Spark Version 3.5.0\n",
      "Spark UI is available at: http://10.206.101.44:4040\n"
     ]
    }
   ],
   "source": [
    "print(\"Using Apache Spark Version\", spark.version)\n",
    "web_ui_url = sc.uiWebUrl\n",
    "print(f\"Spark UI is available at: {web_ui_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fd7aec8e1b1fcb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:19:23.011858Z",
     "start_time": "2024-04-27T20:18:01.884568Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/27 16:18:14 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "calendar = spark.read.option(\"header\", \"true\") \\\n",
    "                    .option(\"delimiter\", \",\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .option(\"multiLine\", \"true\")\\\n",
    "                    .option(\"escape\", \"\\\"\")\\\n",
    "                    .csv(\"../Data/calendar.csv\")\n",
    "calendar = calendar.drop(*['minimum_nights','maximum_nights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dee41ed38da655",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:19:23.044171Z",
     "start_time": "2024-04-27T20:19:23.015175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<function __main__.money_to_float(money_str)>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def money_to_float(money_str):\n",
    "    if money_str is None:\n",
    "        return None\n",
    "    else:\n",
    "        cleaned_str = money_str[1:].replace(',', '')\n",
    "        return float(cleaned_str)\n",
    "spark.udf.register(\"money_to_float_udf\", money_to_float, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918f1e1280e44e5d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:19:23.288955Z",
     "start_time": "2024-04-27T20:19:23.043231Z"
    }
   },
   "outputs": [],
   "source": [
    "calendar.createOrReplaceTempView('calendar')\n",
    "sql = '''\n",
    "\n",
    "with calendar_cleaned as ( \n",
    "select\n",
    "    listing_id\n",
    "    ,date\n",
    "    ,if(available='t',1,0) as is_available\n",
    "    ,coalesce(money_to_float_udf(adjusted_price),money_to_float_udf(price)) as price\n",
    "    ,state\n",
    "    ,city\n",
    "    ,data_date as data_download_date\n",
    "from calendar\n",
    ")\n",
    "\n",
    "select\n",
    "    state\n",
    "    ,city\n",
    "    ,date\n",
    "    ,sum(is_available)/count(is_available) as occupancy_rate\n",
    "    ,avg(price) as avg_price\n",
    "from calendar_cleaned t1\n",
    "group by \n",
    "    state\n",
    "    ,city\n",
    "    ,date\n",
    "'''\n",
    "result_neighbourhood = spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3942be803292ac96",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:21:58.704830Z",
     "start_time": "2024-04-27T20:19:23.280367Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "  state       city        date  occupancy_rate   avg_price\n0    ny     albany  2024-03-16        0.809756  142.746341\n1    ny     albany  2024-05-26        0.736585  142.746341\n2    nc  asheville  2024-12-22        0.500000  229.000000\n3    tx     austin  2024-09-19        0.323238  375.446479\n4    ma     boston  2024-02-20        0.657231  234.703853",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>city</th>\n      <th>date</th>\n      <th>occupancy_rate</th>\n      <th>avg_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ny</td>\n      <td>albany</td>\n      <td>2024-03-16</td>\n      <td>0.809756</td>\n      <td>142.746341</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ny</td>\n      <td>albany</td>\n      <td>2024-05-26</td>\n      <td>0.736585</td>\n      <td>142.746341</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>nc</td>\n      <td>asheville</td>\n      <td>2024-12-22</td>\n      <td>0.500000</td>\n      <td>229.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tx</td>\n      <td>austin</td>\n      <td>2024-09-19</td>\n      <td>0.323238</td>\n      <td>375.446479</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ma</td>\n      <td>boston</td>\n      <td>2024-02-20</td>\n      <td>0.657231</td>\n      <td>234.703853</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result_neighbourhood.count())\n",
    "result_neighbourhood.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d595dcbfe00ec2",
   "metadata": {},
   "source": [
    "# insert into Database (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e607f1ff70df573",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:21:58.706493Z",
     "start_time": "2024-04-27T20:21:58.691165Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4698c04f0056df27",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T20:21:58.706577Z",
     "start_time": "2024-04-27T20:21:58.692886Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
